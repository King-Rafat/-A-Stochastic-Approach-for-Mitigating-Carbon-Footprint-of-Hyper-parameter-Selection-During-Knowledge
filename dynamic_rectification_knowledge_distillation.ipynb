{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":4874,"status":"ok","timestamp":1660422386012,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"1tPvhCDQBHZc","outputId":"84cc19a2-965c-4cff-84b1-165f25b0052b"},"outputs":[{"output_type":"stream","name":"stdout","text":["11.3\n","0.13.1+cu113\n"]},{"output_type":"execute_result","data":{"text/plain":["'0.12.1+cu113'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import tensorflow as tf\n","import torch\n","print(torch.version.cuda)\n","import torchvision\n","print(torchvision.__version__)\n","import torchaudio\n","torchaudio.__version__"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1660422386013,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"4EbKUWCP2P_g","outputId":"8e84d368-c41a-4a58-d8f8-1f3906222e8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Aug 13 20:26:24 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26647,"status":"ok","timestamp":1660422412650,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"z-9OvyFfRUUV","outputId":"d6bad861-655d-4e92-ad25-3d751ca8c6b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660422412651,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"tCkPGGtH9B06"},"outputs":[],"source":["# !7z x <> -o '/content/drive/MyDrive/Colab Notebooks/465/dynamic_rectification_knowledge_distillation/data'"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1660422412652,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"I08gXM_k2TCO","outputId":"7733f71a-b02d-4b17-c5f2-c94c0e1d3c35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","\n","Tesla T4\n","Memory Usage:\n","Allocated: 0.0 GB\n","Cached:    0.0 GB\n"]}],"source":["# setting device on GPU if available, else CPU\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()\n","\n","#Additional Info when using cuda\n","if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    print('Memory Usage:')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1660422412653,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"YULsOPv82d0t","outputId":"3a9b856b-7256-4402-c237-f81fae493f48"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/465/dynamic_rectification_knowledge_distillation\n"]}],"source":["%cd '/content/drive/MyDrive/Colab Notebooks/465/dynamic_rectification_knowledge_distillation'"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124516,"status":"ok","timestamp":1660422537160,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"SBURx2Mw2guZ","outputId":"5557cd3d-43b0-4ea4-c535-da23421ed164"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi) (2.21)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ConfigArgParse\n","  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n","Installing collected packages: ConfigArgParse\n","Successfully installed ConfigArgParse-1.5.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (0.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gast in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: grpcio in /usr/local/lib/python3.7/dist-packages (1.47.0)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Markdown in /usr/local/lib/python3.7/dist-packages (3.4.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from Markdown) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->Markdown) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->Markdown) (3.8.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mkl-fft\n","  Downloading mkl_fft-1.3.1-16-cp37-cp37m-manylinux2014_x86_64.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.22.0,>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (1.21.6)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2019.0)\n","Collecting dpcpp_cpp_rt\n","  Downloading dpcpp_cpp_rt-2022.1.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 37.2 MB/s \n","\u001b[?25hRequirement already satisfied: intel-openmp==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2022.1.0)\n","Collecting intel-cmplr-lib-rt==2022.1.0\n","  Downloading intel_cmplr_lib_rt-2022.1.0-py2.py3-none-manylinux1_x86_64.whl (37.2 MB)\n","\u001b[K     |████████████████████████████████| 37.2 MB 392 kB/s \n","\u001b[?25hCollecting intel-cmplr-lic-rt==2022.1.0\n","  Downloading intel_cmplr_lic_rt-2022.1.0-py2.py3-none-manylinux1_x86_64.whl (18 kB)\n","Collecting intel-opencl-rt==2022.1.0\n","  Downloading intel_opencl_rt-2022.1.0-py2.py3-none-manylinux1_x86_64.whl (232.4 MB)\n","\u001b[K     |████████████████████████████████| 232.4 MB 5.9 kB/s \n","\u001b[?25hCollecting tbb==2021.*\n","  Downloading tbb-2021.6.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 61.0 MB/s \n","\u001b[?25hInstalling collected packages: tbb, intel-cmplr-lic-rt, intel-opencl-rt, intel-cmplr-lib-rt, dpcpp-cpp-rt, mkl-fft\n","Successfully installed dpcpp-cpp-rt-2022.1.0 intel-cmplr-lib-rt-2022.1.0 intel-cmplr-lic-rt-2022.1.0 intel-opencl-rt-2022.1.0 mkl-fft-1.3.1 tbb-2021.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mkl-random\n","  Downloading mkl_random-1.2.2-16-cp37-cp37m-manylinux2014_x86_64.whl (379 kB)\n","\u001b[K     |████████████████████████████████| 379 kB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-random) (2019.0)\n","Requirement already satisfied: numpy<1.22.0,>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from mkl-random) (1.21.6)\n","Requirement already satisfied: dpcpp_cpp_rt in /usr/local/lib/python3.7/dist-packages (from mkl-random) (2022.1.0)\n","Requirement already satisfied: intel-opencl-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-random) (2022.1.0)\n","Requirement already satisfied: intel-cmplr-lic-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-random) (2022.1.0)\n","Requirement already satisfied: intel-cmplr-lib-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-random) (2022.1.0)\n","Requirement already satisfied: intel-openmp==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-random) (2022.1.0)\n","Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from intel-opencl-rt==2022.1.0->dpcpp_cpp_rt->mkl-random) (2021.6.0)\n","Installing collected packages: mkl-random\n","Successfully installed mkl-random-1.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting olefile\n","  Downloading olefile-0.46.zip (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 6.9 MB/s \n","\u001b[?25hBuilding wheels for collected packages: olefile\n","  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=c4b83ba1586c6a44703b6702625d074419d3ecba5f159cc3551788cedc71c795\n","  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n","Successfully built olefile\n","Installing collected packages: olefile\n","Successfully installed olefile-0.46\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (2.21)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tb-nightlya (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tb-nightlya\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.47.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.4.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.13.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.12.1+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchtext) (4.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Werkzeug in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n","Collecting scikit-image\n","  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n","\u001b[K     |████████████████████████████████| 13.5 MB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.9.0)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.7.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n","Installing collected packages: scikit-image\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","Successfully installed scikit-image-0.19.3\n"]}],"source":["!pip install absl-py\n","!pip install astor\n","!pip install certifi\n","!pip install cffi\n","!pip install chardet\n","!pip install ConfigArgParse\n","!pip install future\n","!pip install gast\n","!pip install grpcio\n","!pip install idna\n","!pip install Markdown\n","!pip install mkl-fft\n","!pip install mkl-random\n","!pip install numpy\n","!pip install olefile\n","!pip install Pillow\n","!pip install protobuf\n","!pip install pycparser\n","!pip install requests\n","!pip install scipy\n","!pip install six\n","!pip install tb-nightlya\n","!pip install tensorboard\n","!pip install tensorboardX\n","!pip install tensorflow\n","!pip install termcolor\n","!pip install torch\n","!pip install torchtext\n","!pip install torchvision\n","!pip install tqdm\n","!pip install urllib3\n","!pip install Werkzeug\n","\n","!pip install -U scikit-image\n","#!pip install ipykernel"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":792,"status":"ok","timestamp":1660422537933,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"Y-F9ZHpj2996","outputId":"37e87fab-60f7-4cda-b0d5-7fc1e73be4e7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n","  from .collection import imread_collection_wrapper\n"]}],"source":["from torch.utils.data import Dataset, DataLoader\n","from skimage import io\n","import cv2\n","import glob\n","import random\n","\n","import torchvision.transforms as transforms\n","\n","\n","\n","data_transforms = {\n","            'train': transforms.Compose([\n","                transforms.ToPILImage(),\n","                transforms.RandomRotation(20),\n","                transforms.RandomHorizontalFlip(0.5),\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.4802, 0.4481, 0.3975], [\n","                                     0.2302, 0.2265, 0.2262]),\n","            ]),\n","            'val': transforms.Compose([\n","                transforms.ToPILImage(),\n","                transforms.ToTensor(),\n","                transforms.Normalize([0.4802, 0.4481, 0.3975], [\n","                                     0.2302, 0.2265, 0.2262]),\n","            ])\n","        }\n","\n","\n","####################################################\n","#       Create Train and Val sets\n","####################################################\n","def flatten(t):\n","    return [item for sublist in t for item in sublist]\n","\n","\n","def generate_train_val_image_path():\n","    train_data_path = 'C:\\\\Users\\\\ACER\\\\Downloads\\\\dynamic_rectification_knowledge_distillation-20220424T131329Z-001\\\\dynamic_rectification_knowledge_distillation\\\\data\\\\tiny-imagenet-200\\\\train'\n","    val_data_path = 'C:\\\\Users\\\\ACER\\\\Downloads\\\\dynamic_rectification_knowledge_distillation-20220424T131329Z-001\\\\dynamic_rectification_knowledge_distillation\\\\data\\\\tiny-imagenet-200\\\\val'\n","\n","    train_image_paths = []  # to store image paths in list\n","    classes = []  # to store class values\n","\n","    for data_path in glob.glob(train_data_path + '\\\\*'):\n","        classes.append(data_path.split('\\\\')[-1])\n","        train_image_paths.append(glob.glob(data_path + '\\\\*'))\n","        \n","    train_image_paths = list(flatten(train_image_paths))\n","    random.shuffle(train_image_paths)\n","\n","    print('train_image_path example: ', train_image_paths[0])\n","    print('class example: ', classes[0])\n","\n","    # 3.\n","    # create the val\n","    val_image_paths = []\n","    for data_path in glob.glob(val_data_path + '/images'):\n","        val_image_paths.append(glob.glob(data_path + '/*/*'))\n","\n","    val_image_paths = list(flatten(val_image_paths))\n","\n","    print(\"Train size: {}\\nValid size: {}\\n\".format(len(train_image_paths), len(val_image_paths)))\n","    print('val_image_path example: ', val_image_paths[0])\n","    print('class example: ', classes[0])\n","    idx_to_class = {i: j for i, j in enumerate(classes)}\n","    class_to_idx = {value: key for key, value in idx_to_class.items()}\n","\n","    return train_image_paths, val_image_paths, idx_to_class, class_to_idx, classes\n","\n","\n","\n","\n","#######################################################\n","#               Define Dataset Class\n","#######################################################\n","\n","class TinyImagenetDataset(Dataset):\n","    def __init__(self, image_paths, class_to_idx, use_cache = True, cache_size = 50000 ,transform = None):\n","        self.image_paths = image_paths\n","        self.transform = transform\n","        self.cached_data = []\n","        self.cache_size = cache_size\n","        self.cache = {}\n","        self.class_to_idx = class_to_idx\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index):\n","        if index in self.cache:\n","            image, label = self.cache[index]\n","        else:\n","            image_filepath = self.image_paths[index]\n","            image_filepath = image_filepath.replace('\\\\', '/')\n","            image = io.imread(image_filepath) # your slow data loading\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            label = image_filepath.split('/')[-2]\n","            label = self.class_to_idx[label]\n","            if len(self.cache) < self.cache_size:\n","                self.cache[index] = (image, label)\n","        \n","        \n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","def get_final_train_and_test_set():\n","    train_image_paths, val_image_paths, idx_to_class, class_to_idx, classes = generate_train_val_image_path()\n","\n","    trainset = TinyImagenetDataset(train_image_paths, class_to_idx, transform=data_transforms['train'])\n","#     print(train_image_paths)\n","    devset = TinyImagenetDataset(val_image_paths, class_to_idx, transform=data_transforms['val'])\n","#     print(val_image_paths)\n","    return trainset, devset"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1660422537937,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"KzUNDqUo2_t5"},"outputs":[],"source":["##################################################################\n","#   Utils\n","##################################################################\n","\n","\n","\"\"\"\n","Tensorboard logger code referenced from:\n","https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/\n","Other helper functions:\n","https://github.com/cs230-stanford/cs230-stanford.github.io\n","\"\"\"\n","import tensorflow as tf\n","import json\n","import logging\n","import os\n","import shutil\n","import torch\n","from collections import OrderedDict\n","from torch.optim.lr_scheduler import _LRScheduler\n","import numpy as np\n","import scipy.misc \n","try:\n","    from StringIO import StringIO  # Python 2.7\n","except ImportError:\n","    from io import BytesIO         # Python 3.x\n","\n","\n","class Params():\n","    \"\"\"Class that loads hyperparameters from a json file.\n","\n","    Example:\n","    ```\n","    params = Params(json_path)\n","    print(params.learning_rate)\n","    params.learning_rate = 0.5  # change the value of learning_rate in params\n","    ```\n","    \"\"\"\n","\n","    def __init__(self, json_path):\n","        with open(json_path) as f:\n","            params = json.load(f)\n","            self.__dict__.update(params)\n","\n","    def save(self, json_path):\n","        with open(json_path, 'w') as f:\n","            json.dump(self.__dict__, f, indent=4)\n","            \n","    def update(self, json_path):\n","        \"\"\"Loads parameters from json file\"\"\"\n","        with open(json_path) as f:\n","            params = json.load(f)\n","            self.__dict__.update(params)\n","\n","    @property\n","    def dict(self):\n","        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']\"\"\"\n","        return self.__dict__\n","\n","\n","class RunningAverage():\n","    \"\"\"A simple class that maintains the running average of a quantity\n","    \n","    Example:\n","    ```\n","    loss_avg = RunningAverage()\n","    loss_avg.update(2)\n","    loss_avg.update(4)\n","    loss_avg() = 3\n","    ```\n","    \"\"\"\n","    def __init__(self):\n","        self.steps = 0\n","        self.total = 0\n","    \n","    def update(self, val):\n","        self.total += val\n","        self.steps += 1\n","    \n","    def __call__(self):\n","        return self.total/float(self.steps)\n","\n","class AverageMeter(object):\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val*n\n","        self.count += n\n","        self.avg = self.sum/self.count\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def set_logger(log_path):\n","    \"\"\"Set the logger to log info in terminal and file `log_path`.\n","\n","    In general, it is useful to have a logger so that every output to the terminal is saved\n","    in a permanent file. Here we save it to `model_dir/train.log`.\n","\n","    Example:\n","    ```\n","    logging.info(\"Starting training...\")\n","    ```\n","\n","    Args:\n","        log_path: (string) where to log\n","    \"\"\"\n","    logger = logging.getLogger()\n","    logger.setLevel(logging.INFO)\n","\n","    if not logger.handlers:\n","        # Logging to a file\n","        file_handler = logging.FileHandler(log_path)\n","        file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n","        logger.addHandler(file_handler)\n","\n","        # Logging to console\n","        stream_handler = logging.StreamHandler()\n","        stream_handler.setFormatter(logging.Formatter('%(message)s'))\n","        logger.addHandler(stream_handler)\n","\n","\n","def save_dict_to_json(d, json_path):\n","    \"\"\"Saves dict of floats in json file\n","\n","    Args:\n","        d: (dict) of float-castable values (np.float, int, float, etc.)\n","        json_path: (string) path to json file\n","    \"\"\"\n","    with open(json_path, 'w') as f:\n","        # We need to convert the values to float for json (it doesn't accept np.array, np.float, )\n","        d = {k: float(v) for k, v in d.items()}\n","        json.dump(d, f, indent=4)\n","\n","\n","def save_checkpoint(state, is_best, checkpoint, epoch_checkpoint = False):\n","    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n","    checkpoint + 'best.pth.tar'\n","\n","    Args:\n","        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n","        is_best: (bool) True if it is the best model seen till now\n","        checkpoint: (string) folder where parameters are to be saved\n","    \"\"\"\n","    filepath = os.path.join(checkpoint, 'last.pth.tar')\n","    if not os.path.exists(checkpoint):\n","        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n","        os.mkdir(checkpoint)\n","    else:\n","        print(\"Checkpoint Directory exists! \")\n","    torch.save(state, filepath)\n","    if is_best:\n","        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n","    if epoch_checkpoint == True:\n","        epoch_file = str(state['epoch']-1) + '.pth.tar'\n","        shutil.copyfile(filepath, os.path.join(checkpoint, epoch_file))\n","\n","\n","\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer=None):\n","    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n","    optimizer assuming it is present in checkpoint.\n","\n","    Args:\n","        checkpoint: (string) filename which needs to be loaded\n","        model: (torch.nn.Module) model for which the parameters are loaded\n","        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n","    \"\"\"\n","    try:\n","\n","      if not os.path.exists(checkpoint):\n","        raise FileNotFoundError\n","    except FileNotFoundError:\n","      (\"File doesn't exist {}\".format(checkpoint))\n","\n","    if torch.cuda.is_available():\n","        checkpoint = torch.load(checkpoint)\n","    else:\n","        # this helps avoid errors when loading single-GPU-trained weights onto CPU-model\n","        checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n","\n","    model.load_state_dict(checkpoint['state_dict'])\n","\n","    if optimizer:\n","        optimizer.load_state_dict(checkpoint['optim_dict'])\n","\n","    return checkpoint\n","\n","\n","class WarmUpLR(_LRScheduler):\n","    \"\"\"warmup_training learning rate scheduler\n","    Args:\n","        optimizer: optimzier(e.g. SGD)\n","        total_iters: totoal_iters of warmup phase\n","    \"\"\"\n","\n","    def __init__(self, optimizer, total_iters, last_epoch=-1):\n","        self.total_iters = total_iters\n","        super().__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        \"\"\"we will use the first m batches, and set the learning\n","        rate to base_lr * m / total_iters\n","        \"\"\"\n","        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1570,"status":"ok","timestamp":1660422539497,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"oydFZd_m3BLh"},"outputs":[],"source":["##################################################################\n","#   Data Loader\n","##################################################################\n","\n","\"\"\"\n","   CIFAR-10 CIFAR-100, Tiny-ImageNet data loader\n","\"\"\"\n","\n","import os\n","import random\n","\n","import numpy as np\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","def fetch_dataloader(types, params, dataset_name=None):\n","    \"\"\"\n","    Fetch and return train/dev dataloader with hyperparameters (params.subset_percent = 1.)\n","    \"\"\"\n","    # using random crops and horizontal flip for train set\n","    if params.augmentation == \"yes\":\n","        train_transformer = transforms.Compose([\n","            transforms.RandomCrop(\n","                32, padding=4),\n","            transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n","            transforms.RandomRotation(15),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343),\n","                                 (0.2673342858792401, 0.2564384629170883, 0.27615047132568404))])\n","        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.240, 0.243, 0.261))\n","\n","    # data augmentation can be turned off\n","    else:\n","        train_transformer = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343),\n","                                 (0.2673342858792401, 0.2564384629170883, 0.27615047132568404))])\n","\n","    # transformer for dev set\n","    dev_transformer = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343),\n","                             (0.2673342858792401, 0.2564384629170883, 0.27615047132568404))])\n","\n","    # Deciding Dataset\n","    if dataset_name == None:\n","        if params.dataset == 'cifar10':\n","            trainset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=True,\n","                                                    download=True, transform=train_transformer)\n","            devset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=False,\n","                                                  download=True, transform=dev_transformer)\n","        elif params.dataset == 'cifar100':\n","            trainset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=True,\n","                                                     download=True, transform=train_transformer)\n","            devset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=False,\n","                                                   download=True, transform=dev_transformer)\n","        elif params.dataset == 'mnist':\n","            trainset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=True,\n","                                                  download=True, transform=train_transformer)\n","            devset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=False,\n","                                                download=True, transform=dev_transformer)\n","        elif params.dataset == 'tiny_imagenet':\n","            trainset, devset = get_final_train_and_test_set()\n","\n","\n","    else:\n","        print(\"Dataset Name :  ----------     \" + str(dataset_name) + \"     ----------\")\n","        if dataset_name == 'cifar10':\n","            trainset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=True,\n","                                                    download=True, transform=train_transformer)\n","            devset = torchvision.datasets.CIFAR10(root='./data/data-cifar10', train=False,\n","                                                  download=True, transform=dev_transformer)\n","        elif dataset_name == 'cifar100':\n","            trainset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=True,\n","                                                     download=True, transform=train_transformer)\n","            devset = torchvision.datasets.CIFAR100(root='./data/data-cifar100', train=False,\n","                                                   download=True, transform=dev_transformer)\n","        elif dataset_name == 'mnist':\n","            trainset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=True,\n","                                                  download=True, transform=train_transformer)\n","            devset = torchvision.datasets.MNIST(root='./data/data-MNIST', train=False,\n","                                                download=True, transform=dev_transformer)\n","        elif dataset_name == 'tiny_imagenet':\n","            trainset, devset = get_final_train_and_test_set()\n","            # data_dir = './data/tiny-imagenet-200/'\n","            # data_transforms = {\n","            #     'train': transforms.Compose([\n","            #         transforms.RandomRotation(20),\n","            #         transforms.RandomHorizontalFlip(0.5),\n","            #         transforms.ToTensor(),\n","            #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n","            #     ]),\n","            #     'val': transforms.Compose([\n","            #         transforms.ToTensor(),\n","            #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n","            #     ])\n","            # }\n","            # train_dir = data_dir + 'train/'\n","            # test_dir = data_dir + 'val/'\n","            # trainset = torchvision.datasets.ImageFolder(train_dir, data_transforms['train'])\n","            # devset = torchvision.datasets.ImageFolder(test_dir, data_transforms['val'])\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=params.batch_size, shuffle=True, num_workers=params.num_workers)\n","    devloader = torch.utils.data.DataLoader(devset, batch_size=params.batch_size, shuffle=False, num_workers=params.num_workers)\n","    \n","    if types == 'train':\n","        dl = trainloader\n","    else:\n","        dl = devloader\n","\n","    return dl\n","\n","\n","def fetch_subset_dataloader(types, params):\n","    \"\"\"\n","    Use only a subset of dataset for KD training, depending on params.subset_percent\n","    \"\"\"\n","\n","    # using random crops and horizontal flip for train set\n","    if params.augmentation == \"yes\":\n","        train_transformer = transforms.Compose([\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n","\n","    # data augmentation can be turned off\n","    else:\n","        train_transformer = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n","\n","    # transformer for dev set\n","    dev_transformer = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n","\n","    if params.dataset == 'cifar10':\n","        trainset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=True,\n","                                                download=True, transform=train_transformer)\n","        devset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=False,\n","                                              download=True, transform=dev_transformer)\n","    elif params.dataset == 'cifar100':\n","        trainset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=True,\n","                                                download=True, transform=train_transformer)\n","        devset = torchvision.datasets.CIFAR10(root='./data-cifar10', train=False,\n","                                              download=True, transform=dev_transformer)\n","    elif params.dataset == 'tiny_imagenet':\n","        trainset, devset = get_final_train_and_test_set()\n","        # data_dir = './data/tiny-imagenet-200/'\n","        # data_transforms = {\n","        #     'train': transforms.Compose([\n","        #         transforms.RandomRotation(20),\n","        #         transforms.RandomHorizontalFlip(0.5),\n","        #         transforms.ToTensor(),\n","        #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n","        #     ]),\n","        #     'val': transforms.Compose([\n","        #         transforms.ToTensor(),\n","        #         transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n","        #     ])\n","        # }\n","        # train_dir = data_dir + 'train/'\n","        # test_dir = data_dir + 'val/'\n","        # trainset = torchvision.datasets.ImageFolder(train_dir, data_transforms['train'])\n","        # devset = torchvision.datasets.ImageFolder(test_dir, data_transforms['val'])\n","\n","    trainset_size = len(trainset)\n","    indices = list(range(trainset_size))\n","    split = int(np.floor(params.subset_percent * trainset_size))\n","    np.random.seed(230)\n","    np.random.shuffle(indices)\n","\n","    train_sampler = SubsetRandomSampler(indices[:split])\n","\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=params.batch_size,\n","                                              sampler=train_sampler, num_workers=params.num_workers)\n","\n","    devloader = torch.utils.data.DataLoader(devset, batch_size=params.batch_size,\n","                                            shuffle=False, num_workers=params.num_workers)\n","   # print(trainset[0])\n","    if types == 'train':\n","        dl = trainloader\n","    else:\n","        dl = devloader\n","\n","    return dl\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1660422539501,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"ofTgWLb83DCj"},"outputs":[],"source":["##################################################################\n","#   Evaluate\n","##################################################################\n","\n","\"\"\"Evaluates the model\"\"\"\n","\n","import argparse\n","import logging\n","import torch\n","from torch.autograd import Variable\n","\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--model_dir', default='experiments/base_model',\n","                    help=\"Directory of params.json\")\n","parser.add_argument('--restore_file', default='best', help=\"name of the file in --model_dir \\\n","                     containing weights to load\")\n","\n","\n","def evaluate(model, loss_fn, dataloader, params, args):\n","    \"\"\"Evaluate the model on `num_steps` batches.\n","\n","    Args:\n","        model: (torch.nn.Module) the neural network\n","        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n","        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n","        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n","        params: (Params) hyperparameters\n","        num_steps: (int) number of batches to train on, each of size params.batch_size\n","    \"\"\"\n","\n","    # set model to evaluation mode\n","    model.eval()\n","    losses = AverageMeter()\n","    total = 0\n","    correct = 0\n","\n","    # compute metrics over the dataset\n","    for data_batch, labels_batch in dataloader:\n","        data_batch, labels_batch = data_batch.to(device), labels_batch.to(device)\n","\n","        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n","        # compute model output\n","        output_batch = model(data_batch)\n","        if args.regularization:\n","            loss = loss_fn(output_batch, labels_batch, params)\n","        else:\n","            loss = loss_fn(output_batch, labels_batch)\n","\n","        losses.update(loss.data, data_batch.size(0))\n","        _, predicted = output_batch.max(1)\n","        total += labels_batch.size(0)\n","        correct += predicted.eq(labels_batch).sum().item()\n","\n","    loss_avg = losses.avg\n","    acc = 100.*correct/total\n","    logging.info(\n","        \"- Eval metrics, acc:{acc:.4f}, loss: {loss_avg:.4f}\".format(acc=acc, loss_avg=loss_avg))\n","    my_metric = {'accuracy': acc, 'loss': loss_avg}\n","    return my_metric\n","\n","\n","\"\"\"\n","This function duplicates \"evaluate()\" but ignores \"loss_fn\" simply for speedup purpose.\n","Validation loss during KD mode would display '0' all the time.\n","One can bring that info back by using the fetched teacher outputs during evaluation (refer to train.py)\n","\"\"\"\n","\n","\n","def evaluate_kd(model, dataloader, params):\n","    \"\"\"Evaluate the model on `num_steps` batches.\n","\n","    Args:\n","        model: (torch.nn.Module) the neural network\n","        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n","        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n","        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n","        params: (Params) hyperparameters\n","        num_steps: (int) number of batches to train on, each of size params.batch_size\n","    \"\"\"\n","\n","    # set model to evaluation mode\n","    model.eval()\n","    total = 0\n","    correct = 0\n","\n","    # compute metrics over the dataset\n","    for i, (data_batch, labels_batch) in enumerate(dataloader):\n","        # move to GPU if available\n","        data_batch, labels_batch = data_batch.to(device), labels_batch.to(device)\n","        # fetch the next evaluation batch\n","        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n","\n","        # compute model output\n","        output_batch = model(data_batch)\n","\n","        # loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch, params)\n","        loss = 0.0  # force validation loss to zero to reduce computation time\n","        _, predicted = output_batch.max(1)\n","        total += labels_batch.size(0)\n","        correct += predicted.eq(labels_batch).sum().item()\n","\n","    acc = 100. * correct / total\n","    logging.info(\"- Eval metrics, acc:{acc:.4f}, loss: {loss:.4f}\".format(acc=acc, loss=loss))\n","    my_metric = {'accuracy': acc, 'loss': loss}\n","    #my_metric['accuracy'] = acc\n","    return my_metric\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1660422539502,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"KvwDgGPs3bmS"},"outputs":[],"source":["##################################################################\n","#   My loss functions\n","##################################################################\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import random\n","\n","def my_relu(x):\n","    return torch.maximum(x, torch.zeros_like(x))\n","\n","def s_ratio(x):\n","    x = my_relu(x)\n","    x = torch.add(x,1)\n","    s = torch.sum(x,1)\n","    for i in range(len(x)):\n","        x[i] = torch.div(x[i].clone(),s[i])\n","    \n","    return x\n","\n","def loss_kd(outputs, labels, teacher_outputs, params):\n","    \"\"\"\n","    loss function for Knowledge Distillation (KD)\n","    \"\"\"\n","    alpha = params.alpha\n","    T = random.randint(2,20)\n","    \n","    KD_loss = nn.MSELoss()(outputs,\n","                          teacher_outputs)\n","\n","\n","    return KD_loss\n","\n","\n","# def dynamic_rectification(outputs, labels):\n","#     _, predicted = outputs.max(1)\n","#     correct = predicted.eq(labels)\n","\n","#     for i in range(correct.shape[0]):\n","#         if correct[i].item() == False:\n","#             c_index = labels[i].item()\n","#             p_index = predicted[i].item()\n","#             tmp1, tmp2 = outputs[i, p_index].item(), outputs[i, c_index].item()\n","#             outputs[i, c_index] = tmp1\n","#             outputs[i, p_index] = tmp2\n","    \n","#     return outputs\n","\n","def loss_swap(outputs, labels):\n","    _, predicted = outputs.max(1)\n","    tmp = outputs[torch.arange(len(labels)), predicted]\n","    outputs[torch.arange(len(labels)), predicted] = outputs[torch.arange(\n","        len(labels)), labels]\n","    outputs[torch.arange(len(labels)), labels] = tmp\n","    return outputs\n","\n","\n","def loss_kd_self(outputs, labels, teacher_outputs, params, swap_option='None'):\n","    \"\"\"\n","    loss function for self training: Tf-KD_{self}\n","    \"\"\"\n","    alpha = params.alpha\n","    T = params.temperature\n","    \"\"\"\n","        Swapping the outputs here\n","        student_probability_swap || teacher_probability_swap \n","    \"\"\"\n","    if swap_option == 'student_probability_swap':\n","        outputs = loss_swap(outputs, labels)\n","    elif swap_option == 'teacher_probability_swap':\n","        teacher_outputs = loss_swap(teacher_outputs, labels)\n","\n","    loss_CE = F.cross_entropy(outputs, labels)\n","    D_KL = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1), F.softmax(teacher_outputs/T, dim=1)) * \\\n","        (T * T) * params.multiplier  # multiple is 1.0 in most of cases, some cases are 10 or 50\n","    KD_loss = (1. - alpha)*loss_CE + alpha*D_KL\n","\n","    return KD_loss\n","\n","\n","def loss_kd_regularization(outputs, labels, params):\n","    \"\"\"\n","    loss function for mannually-designed regularization: Tf-KD_{reg}\n","    \"\"\"\n","    alpha = params.reg_alpha\n","    T = params.reg_temperature\n","    correct_prob = 0.99    # the probability for correct class in u(k)\n","    loss_CE = F.cross_entropy(outputs, labels)\n","    K = outputs.size(1)\n","\n","    teacher_soft = torch.ones_like(outputs).to(device)\n","    teacher_soft = teacher_soft*(1-correct_prob)/(K-1)  # p^d(k)\n","    for i in range(outputs.shape[0]):\n","        teacher_soft[i, labels[i]] = correct_prob\n","    loss_soft_regu = nn.KLDivLoss()(F.log_softmax(outputs, dim=1),\n","                                    F.softmax(teacher_soft/T, dim=1))*params.multiplier\n","\n","    KD_loss = (1. - alpha)*loss_CE + alpha*loss_soft_regu\n","\n","    return KD_loss\n","\n","\n","def loss_kd_self_plus_regularization(outputs, labels, teacher_outputs, params, swap_option='None'):\n","\n","    new_alpha = 0.45\n","   \n","    #loss function for self training: Tf-KD_{self}\n","    alpha_self = params.alpha\n","    T = params.temperature\n","    \"\"\"\n","        Swapping the outputs here\n","        student_probability_swap || teacher_probability_swap \n","    \"\"\"\n","    if swap_option == 'student_probability_swap':\n","        outputs = loss_swap(outputs, labels)\n","    elif swap_option == 'teacher_probability_swap':\n","        teacher_outputs = loss_swap(teacher_outputs, labels)\n","\n","    loss_CE = F.cross_entropy(outputs, labels)\n","    D_KL_Self = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1), F.softmax(teacher_outputs/T, dim=1)) * \\\n","        (T * T) * params.multiplier  # multiple is 1.0 in most of cases, some cases are 10 or 50\n","    \n","\n","\n","    #loss function for mannually-designed regularization: Tf-KD_{reg}\n","    alpha_reg = params.reg_alpha\n","    T = params.reg_temperature\n","    correct_prob = 0.99    # the probability for correct class in u(k)\n","    loss_CE = F.cross_entropy(outputs, labels)\n","    K = outputs.size(1)\n","\n","    teacher_soft = torch.ones_like(outputs).to(device)\n","    teacher_soft = teacher_soft*(1-correct_prob)/(K-1)  # p^d(k)\n","    for i in range(outputs.shape[0]):\n","        teacher_soft[i, labels[i]] = correct_prob\n","    loss_soft_regu = nn.KLDivLoss()(F.log_softmax(outputs, dim=1),F.softmax(teacher_soft/T, dim=1))*params.multiplier\n","\n","\n","\n","    # final loss \n","    KD_loss = (1. - alpha_reg)*loss_CE + new_alpha*loss_soft_regu + new_alpha*D_KL_Self\n","\n","    return KD_loss\n","\n","\n","\n","\n","\n","def loss_label_smoothing(outputs, labels):\n","    \"\"\"\n","    loss function for label smoothing regularization\n","    \"\"\"\n","    alpha = 0.1\n","    N = outputs.size(0)  # batch_size\n","    C = outputs.size(1)  # number of classes\n","    smoothed_labels = torch.full(\n","        size=(N, C), fill_value=alpha / (C - 1)).to(device)\n","    smoothed_labels.scatter_(\n","        dim=1, index=torch.unsqueeze(labels, dim=1), value=1-alpha)\n","\n","    log_prob = torch.nn.functional.log_softmax(outputs, dim=1)\n","    loss = -torch.sum(log_prob * smoothed_labels) / N\n","\n","    return loss\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":523,"status":"ok","timestamp":1660422540013,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"Lqzn15bF3dJK"},"outputs":[],"source":["##################################################################\n","#   Train functions\n","##################################################################\n","\n","\n","import os\n","import time\n","import math\n","from tqdm import tqdm\n","import logging\n","from torch.autograd import Variable\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.optim.lr_scheduler import StepLR, MultiStepLR\n","\n","\n","\n","# KD train and evaluate\n","def train_and_evaluate_kd(model, teacher_model, train_dataloader, val_dataloader, optimizer,\n","                       loss_fn_kd, warmup_scheduler, params, args, restore_file=None):\n","    \"\"\"\n","    KD Train the model and evaluate every epoch.\n","    \"\"\"\n","    # reload weights from restore_file if specified\n","    if restore_file is not None:\n","        restore_path = os.path.join(args.model_dir, args.restore_file + '.pth.tar')\n","        logging.info(\"Restoring parameters from {}\".format(restore_path))\n","        load_checkpoint(restore_path, model, optimizer)\n","\n","    # tensorboard setting\n","    log_dir = args.model_dir + '/tensorboard/'\n","    writer = SummaryWriter(log_dir=log_dir)\n","\n","    best_val_acc = 0.0\n","    teacher_model.eval()\n","    teacher_acc = evaluate_kd(teacher_model, val_dataloader, params)\n","    print(\">>>>>>>>>The teacher accuracy: {}>>>>>>>>>\".format(teacher_acc['accuracy']))\n","\n","    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 80], gamma=0.2)\n","    for epoch in range(params.num_epochs):\n","\n","        if epoch > 0:   # 0 is the warm up epoch\n","            scheduler.step()\n","        logging.info(\"Epoch {}/{}, lr:{}\".format(epoch + 1, params.num_epochs, optimizer.param_groups[0]['lr']))\n","\n","        # KD Train\n","        train_acc, train_loss = train_kd(model, teacher_model, optimizer, loss_fn_kd, train_dataloader, warmup_scheduler, params, args, epoch)\n","        # Evaluate\n","        val_metrics = evaluate_kd(model, val_dataloader, params)\n","\n","        val_acc = val_metrics['accuracy']\n","        is_best = val_acc>=best_val_acc\n","\n","        # Save weights\n","        save_checkpoint({'epoch': epoch + 1,\n","                               'state_dict': model.state_dict(),\n","                               'optim_dict' : optimizer.state_dict()},\n","                               is_best=is_best,\n","                               checkpoint=args.model_dir)\n","\n","        # If best_eval, best_save_path\n","        if is_best:\n","            logging.info(\"*********** Hurray ! Found new best accuracy *****************\")\n","            best_val_acc = val_acc\n","\n","            # Save best val metrics in a json file in the model directory\n","            file_name = \"eval_best_result.json\"\n","            best_json_path = os.path.join(args.model_dir, file_name)\n","            save_dict_to_json(val_metrics, best_json_path)\n","\n","        # Save latest val metrics in a json file in the model directory\n","        last_json_path = os.path.join(args.model_dir, \"eval_last_result.json\")\n","        save_dict_to_json(val_metrics, last_json_path)\n","\n","        # Tensorboard\n","        writer.add_scalar('Train_accuracy', train_acc, epoch)\n","        writer.add_scalar('Train_loss', train_loss, epoch)\n","        writer.add_scalar('Test_accuracy', val_metrics['accuracy'], epoch)\n","        writer.add_scalar('Test_loss', val_metrics['loss'], epoch)\n","        # export scalar data to JSON for external processing\n","    writer.close()\n","\n","\n","# Defining train_kd functions\n","def train_kd(model, teacher_model, optimizer, loss_fn_kd, dataloader, warmup_scheduler, params, args, epoch, flag=None):\n","    \"\"\"\n","    KD Train the model on `num_steps` batches\n","    \"\"\"\n","    # set model to training mode\n","    model.train()\n","    teacher_model.eval()\n","    loss_avg = RunningAverage()\n","    losses = AverageMeter()\n","    total = 0\n","    correct = 0\n","    # Use tqdm for progress bar\n","    with tqdm(total=len(dataloader)) as t:\n","        for i, (train_batch, labels_batch) in enumerate(dataloader):\n","            if epoch<=0:\n","                warmup_scheduler.step()\n","\n","            train_batch, labels_batch = train_batch.to(device), labels_batch.to(device)\n","            # convert to torch Variables\n","            train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n","            # print(train_batch.shape)\n","            # compute model output, fetch teacher output, and compute KD loss\n","            output_batch = model(train_batch)\n","\n","            # get one batch output from teacher model\n","            output_teacher_batch = teacher_model(train_batch).to(device)\n","            output_teacher_batch = Variable(output_teacher_batch, requires_grad=False)\n","\n","            loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch, params)\n","\n","            # clear previous gradients, compute gradients of all variables wrt loss\n","            optimizer.zero_grad()\n","            loss.backward()\n","            \n","\n","            # performs updates using calculated gradients\n","            optimizer.step()\n","\n","            _, predicted = output_batch.max(1)\n","            total += labels_batch.size(0)\n","            correct += predicted.eq(labels_batch).sum().item()\n","            # update the average loss\n","            loss_avg.update(loss.data)\n","            losses.update(loss.item(), train_batch.size(0))\n","\n","            t.set_postfix(loss='{:05.3f}'.format(loss_avg()), lr='{:05.6f}'.format(optimizer.param_groups[0]['lr']))\n","            t.update()\n","\n","    acc = 100.*correct/total\n","    logging.info(\"- Train accuracy: {acc:.4f}, training loss: {loss:.4f}\".format(acc = acc, loss = losses.avg))\n","    return acc, losses.avg\n","\n","\n","# normal training\n","def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n","                       loss_fn, params, model_dir, warmup_scheduler, args, restore_file=None):\n","    \"\"\"\n","    Train the model and evaluate every epoch.\n","    \"\"\"\n","    # reload weights from restore_file if specified\n","    if restore_file is not None:\n","        restore_path = os.path.join(args.model_dir, args.restore_file + '.pth.tar')\n","        logging.info(\"Restoring parameters from {}\".format(restore_path))\n","        load_checkpoint(restore_path, model, optimizer)\n","\n","    # dir setting, tensorboard events will save in the dirctory\n","    log_dir = args.model_dir + '/base_train/'\n","    if args.regularization:\n","        log_dir = args.model_dir + '/Tf-KD_regularization/'\n","        model_dir = log_dir\n","    elif args.label_smoothing:\n","        log_dir = args.model_dir + '/label_smoothing/'\n","        model_dir = log_dir\n","    writer = SummaryWriter(log_dir=log_dir)\n","\n","    best_val_acc = 0.0\n","\n","    # learning rate schedulers\n","    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 80], gamma=0.2)\n","\n","    for epoch in range(params.num_epochs):\n","        if epoch > 0:   # 1 is the warm up epoch\n","            scheduler.step(epoch)\n","\n","        # Run one epoch\n","        logging.info(\"Epoch {}/{}, lr:{}\".format(epoch + 1, params.num_epochs, optimizer.param_groups[0]['lr']))\n","\n","        # compute number of batches in one epoch (one full pass over the training set)\n","        train_acc, train_loss = train(model, optimizer, loss_fn, train_dataloader, params, epoch, warmup_scheduler, args)\n","\n","        # Evaluate for one epoch on validation set\n","        val_metrics = evaluate(model, loss_fn, val_dataloader, params, args)\n","\n","        val_acc = val_metrics['accuracy']\n","        is_best = val_acc>=best_val_acc\n","\n","        # Save weights\n","        save_checkpoint({'epoch': epoch + 1,\n","                               'state_dict': model.state_dict(),\n","                               'optim_dict' : optimizer.state_dict()},\n","                                is_best=is_best,\n","                                checkpoint=model_dir)\n","        # If best_eval, best_save_path\n","        if is_best:\n","            logging.info(\"- Found new best accuracy\")\n","            best_val_acc = val_acc\n","\n","            # Save best val metrics in a json file in the model directory\n","            best_json_path = os.path.join(model_dir, \"eval_best_results.json\")\n","            save_dict_to_json(val_metrics, best_json_path)\n","\n","        # Save latest val metrics in a json file in the model directory\n","        last_json_path = os.path.join(model_dir, \"eval_last_results.json\")\n","        save_dict_to_json(val_metrics, last_json_path)\n","\n","        # Tensorboard\n","        writer.add_scalar('Train_accuracy', train_acc, epoch)\n","        writer.add_scalar('Train_loss', train_loss, epoch)\n","        writer.add_scalar('Test_accuracy', val_metrics['accuracy'], epoch)\n","        writer.add_scalar('Test_loss', val_metrics['loss'], epoch)\n","    writer.close()\n","\n","\n","# normal training function\n","def train(model, optimizer, loss_fn, dataloader, params, epoch, warmup_scheduler, args):\n","    \"\"\"\n","    Noraml training, without KD\n","    \"\"\"\n","\n","    # set model to training mode\n","    model.train()\n","    loss_avg = RunningAverage()\n","    losses = AverageMeter()\n","    total = 0\n","    correct = 0\n","    # Use tqdm for progress bar\n","    with tqdm(total=len(dataloader)) as t:\n","        for i, data in enumerate(dataloader):\n","            #print(data)\n","#             print(i)\n","            train_batch, labels_batch = data\n","            train_batch, labels_batch = train_batch.cuda(), labels_batch.cuda()\n","            if epoch<=0:\n","                warmup_scheduler.step()\n","            train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n","            optimizer.zero_grad()\n","            output_batch = model(train_batch)\n","            \n","            if args.regularization:\n","                loss = loss_fn(output_batch, labels_batch, params)\n","            else:\n","                loss = loss_fn(output_batch, labels_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            _, predicted = output_batch.max(1)\n","            total += labels_batch.size(0)\n","            correct += predicted.eq(labels_batch).sum().item()\n","\n","            # update the average loss\n","            loss_avg.update(loss.data)\n","            losses.update(loss.data, train_batch.size(0))\n","\n","            t.set_postfix(loss='{:05.3f}'.format(loss_avg()), lr='{:05.6f}'.format(optimizer.param_groups[0]['lr']))\n","            t.update()\n","\n","    acc = 100. * correct / total\n","    logging.info(\"- Train accuracy: {acc: .4f}, training loss: {loss: .4f}\".format(acc=acc, loss=losses.avg))\n","    return acc, losses.avg\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1660422540014,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"XoL7Y0uV3fGp"},"outputs":[],"source":["def read_params_json(json_path):\n","    f = open(json_path)\n","    json_object = json.load(f)\n","    print(\"################## Json Params ##################\")\n","    json_formatted_str = json.dumps(json_object, indent=2)\n","    print(json_formatted_str)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1660422540015,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"efubCvup3gfx"},"outputs":[],"source":["import torchvision\n","import torch.nn as nn\n","from torchvision import datasets, models, transforms\n","def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","\n","def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet50\":\n","        \"\"\" Resnet50\n","        \"\"\"\n","        model_ft = models.resnet50(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","\n","    elif model_name == \"densenet121\":\n","        \"\"\" Densenet121\n","        \"\"\"\n","        model_ft = models.densenet121(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier.in_features\n","        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1660422540017,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"DpoJz6Hz3h6B"},"outputs":[],"source":[" class ArmentPassingClass:\n","  def __init__(self, model_dir, restore_file, num_class, warm, regularization, label_smoothing, double_training, \n","               self_training, swap_option, dataset_name, random_seeder, pt_teacher):\n","    self.model_dir = model_dir\n","    self.restore_file = restore_file\n","    self.num_class = num_class\n","    self.warm = warm\n","    self.regularization = regularization\n","    self.label_smoothing = label_smoothing\n","    self.double_training = double_training\n","    self.self_training = self_training\n","    self.swap_option = swap_option\n","    self.dataset_name = dataset_name\n","    self.random_seeder = random_seeder\n","    self.pt_teacher = pt_teacher\n","\n","dataset_num_class_dict = {'cifar10': 10, 'cifar100': 100, 'tiny_imagenet':200}\n","\n","\n","############# Dataset Assigning #############\n","dataset_name = 'cifar100' \n","num_class = dataset_num_class_dict[dataset_name]\n","restore_file = None\n","\n","\n","############# KD Train #############\n","# model_dir =  'experiments/kd_experiments/shufflenet_distill/shufflenet_self_teacher/' + dataset_name\n","\n","# model_dir =  'experiments/kd_experiments/resnet50_distill/resnet50_self_teacher/' + dataset_name\n","# model_dir =  'experiments/kd_experiments/densenet121_distill/densenet_self_teacher/' + dataset_name\n","# # model_dir =  'experiments/kd_experiments/googlenet_distill/googlenet_self_teacher/' + dataset_name\n","model_dir =  'experiments/kd_experiments/mobilenet_distill/resnet18_teacher/' + dataset_name\n","self_training = False\n","swap_option = 'teacher_probability_swap'\n","\n","\n","\n","############# Base Train #############  \n","# model_dir =  'experiments/base_experiments/base_densenet121/' + dataset_name\n","# # # model_dir =  'experiments/base_experiments/base_resnet50/' + dataset_name\n","# # # # model_dir =  'experiments/base_experiments/base_mobilenetv2/' + dataset_name\n","# self_training = False\n","# swap_option = None\n","\n","\n","\n","\n","args = ArmentPassingClass(  model_dir = model_dir, \n","                            restore_file = restore_file, \n","                            num_class = num_class, \n","                            warm = 1, \n","                            regularization = False, \n","                            label_smoothing = False, \n","                            double_training = False, \n","                            self_training = self_training, \n","                            swap_option = swap_option, \n","                            dataset_name = dataset_name, \n","                            random_seeder = 2320, \n","                            pt_teacher = False)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3534,"status":"ok","timestamp":1660422543539,"user":{"displayName":"Kazi Rafat Haa Meem 1911391642","userId":"18215563768775232044"},"user_tz":-360},"id":"fwEVptNK3jLQ","scrolled":false},"outputs":[],"source":["##################################################################\n","#   Main\n","##################################################################\n","\n","\n","\"\"\"\n","Teacher free KD, main.py\n","\"\"\"\n","import argparse\n","import logging\n","import os\n","import sys\n","import random\n","import warnings\n","\n","\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","from torchsummary import summary\n","\n","# import data_loader as data_loader\n","import model.alexnet as alexnet\n","import model.densenet as densenet\n","import model.googlenet as googlenet\n","import model.mobilenetv2 as mobilenet\n","import model.net as net\n","import model.resnet as resnet\n","import model.resnext as resnext\n","import model.shufflenetv2 as shufflenet\n","# import utils\n","# from my_loss_function import (loss_kd, loss_kd_regularization, loss_kd_self,\n","#                               loss_label_smoothing)\n","# from train_kd import train_and_evaluate, train_and_evaluate_kd\n","from pprint import pprint\n","\n","\n","def main():\n","    # Load the parameters from json file\n","    # args = parser.parse_args(argv[1:])\n","    # args = parser.parse_args()\n","    torch.cuda.empty_cache()\n","    json_path = os.path.join(args.model_dir.rsplit('/',1)[0] , args.dataset_name + '_params.json')\n","    assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n","    params = Params(json_path)\n","    params.num_epochs = 100\n","    # params.batch_size = 64\n","    read_params_json(json_path)\n","    pprint(vars(params))\n","    # Set the random seed for reproducible experiments\n","    random_seeder = int(args.random_seeder)\n","    print('Random Seeder :  {}'.format(random_seeder))\n","    print('Dataset Name : ', args.dataset_name, '  Number of classes: ', args.num_class)\n","    random.seed(random_seeder)\n","    torch.manual_seed(random_seeder)\n","    np.random.seed(random_seeder)\n","    torch.cuda.manual_seed(random_seeder)\n","    warnings.filterwarnings(\"ignore\")\n","\n","    # Set the logger\n","    \n","    if not os.path.exists(args.model_dir):\n","        os.makedirs(args.model_dir)\n","    logger_path = os.path.join(args.model_dir, 'train.log')  \n","    set_logger(logger_path)\n","    \n","    # Create the input data pipeline\n","    logging.info(\"Loading the datasets...\")\n","\n","    # fetch dataloaders, considering full-set vs. sub-set scenarios\n","\n","    if params.subset_percent < 1.0:\n","        train_dl = fetch_subset_dataloader('train', params)\n","    else:\n","        train_dl = fetch_dataloader('train', params, args.dataset_name)\n","    \n","    dev_dl = fetch_dataloader('dev', params, args.dataset_name)\n","\n","    logging.info(\"- done.\")\n","\n","    \"\"\"\n","    Load student and teacher model\n","    \"\"\"\n","    if \"distill\" in params.model_version:\n","      \n","        # Specify the student models\n","        if params.model_version == \"cnn_distill\":  # 5-layers Plain CNN\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = net.Net(params).to(device)\n","\n","        elif params.model_version == \"shufflenet_v2_distill\":\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = shufflenet.shufflenetv2(class_num=args.num_class).to(device)\n","\n","        elif params.model_version == \"mobilenet_v2_distill\":\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = mobilenet.mobilenetv2(class_num=args.num_class).to(device)\n","\n","        elif params.model_version == 'resnet18_distill':\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = resnet.ResNet18(num_classes=args.num_class).to(device)\n","            print(456)\n","\n","        elif params.model_version == 'resnet50_distill':\n","            print(\"Student model: {}\".format(params.model_version))\n","            model_name  = 'resnet50'\n","            num_classes = args.num_class\n","            feature_extract=False\n","            model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","            model = model.to(device)\n","\n","        elif params.model_version == \"alexnet_distill\":\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = alexnet.alexnet(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"vgg19_distill\":\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = models.vgg19_bn(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"googlenet_distill\":\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = googlenet.GoogleNet(num_class=args.num_class).to(device)\n","\n","        elif params.model_version == \"resnext29_distill\":\n","            print(\"Student model: {}\".format(params.model_version))\n","            model = resnext.CifarResNeXt(\n","                cardinality=8, depth=29, num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"densenet121_distill\":\n","            print(\"Student model: {}\".format(params.model_version))\n","            # model_name  = 'densenet121'\n","            # num_classes = args.num_class\n","            # feature_extract=False\n","            # model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","            # model = model.to(device)\n","            model = densenet.densenet121(num_class=args.num_class).to(device)\n","\n","        # optimizer\n","        if params.model_version == \"cnn_distill\":\n","            optimizer = optim.Adam(model.parameters(), lr=params.learning_rate * (params.batch_size / 128))\n","        else:\n","            optimizer = optim.SGD(model.parameters(), lr=params.learning_rate * (params.batch_size / 128), momentum=0.9,\n","                                  weight_decay=5e-4)\n","\n","        iter_per_epoch = len(train_dl)\n","        warmup_scheduler = WarmUpLR(optimizer,iter_per_epoch * args.warm)  # warmup the learning rate in the first epoch\n","\n","        # specify loss function\n","        if args.self_training:\n","            print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>self training>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n","            if args.swap_option == 'student_probability_swap':\n","                print('------------Swapping Student Output------------')\n","            elif args.swap_option == 'teacher_probability_swap':\n","                print('------------Swapping Teacher Output------------')\n","            loss_fn_kd = loss_kd_self\n","        else:\n","            loss_fn_kd = loss_kd\n","\n","        \"\"\" \n","            Specify the pre-trained teacher models for knowledge distillation\n","            Checkpoints can be obtained by regular training or downloading our pretrained models\n","            For model which is pretrained in multi-GPU, use \"nn.DaraParallel\" to correctly load the model weights.\n","        \"\"\"\n","        \n","        model_name_plus_best_pth_tar = args.dataset_name + '/best.pth.tar'\n","        if params.teacher == \"resnet18\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = resnet.ResNet18(num_classes=args.num_class)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet18/' + model_name_plus_best_pth_tar\n","            if args.pt_teacher:  # poorly-trained teacher for Defective KD experiments\n","                teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet18/0.pth.tar'\n","            teacher_model = teacher_model.to(device)\n","\n","        elif params.teacher == \"alexnet\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = alexnet.alexnet(num_classes=args.num_class)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_alexnet/' + model_name_plus_best_pth_tar\n","            teacher_model = teacher_model.to(device)\n","\n","        elif params.teacher == \"googlenet\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = googlenet.GoogleNet(num_class=args.num_class)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_googlenet/' + model_name_plus_best_pth_tar\n","            teacher_model = teacher_model.to(device)\n","\n","        elif params.teacher == \"vgg19\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = models.vgg19_bn(num_classes=args.num_class)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_vgg19/' + model_name_plus_best_pth_tar\n","            teacher_model = teacher_model.to(device)\n","\n","        elif params.teacher == \"resnet50\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            #teacher_model = resnet.ResNet50(num_classes=args.num_class).to(device)\n","            model_name  = params.teacher\n","            num_classes = args.num_class\n","            feature_extract=False\n","            teacher_model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n","            teacher_model = teacher_model.to(device)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet50/' + model_name_plus_best_pth_tar\n","            if args.pt_teacher:  # poorly-trained teacher for Defective KD experiments\n","                teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet50/50.pth.tar'\n","\n","        elif params.teacher == \"densenet121\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            #teacher_model = densenet.densenet121(num_class=args.num_class).to(device)\n","            model_name  = params.teacher\n","            num_classes = args.num_class\n","            feature_extract=False\n","            teacher_model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n","            teacher_model = teacher_model.to(device)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_densenet121/' + model_name_plus_best_pth_tar\n","            # teacher_model = nn.DataParallel(teacher_model).to(device)\n","\n","        elif params.teacher == \"resnet101\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = resnet.ResNet101(num_classes=args.num_class).to(device)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnet101/' + model_name_plus_best_pth_tar\n","            teacher_model = teacher_model.to(device)\n","\n","        elif params.teacher == \"resnext29\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = resnext.CifarResNeXt(cardinality=8, depth=29, num_classes=args.num_class).to(device)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnext29/' + model_name_plus_best_pth_tar\n","            if args.pt_teacher:  # poorly-trained teacher for Defective KD experiments\n","                teacher_checkpoint = 'experiments/pretrained_teacher_models/base_resnext29/50.pth.tar'\n","                teacher_model = nn.DataParallel(teacher_model).to(device)\n","\n","        elif params.teacher == \"mobilenet_v2\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = mobilenet.mobilenetv2(class_num=args.num_class).to(device)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_mobilenet_v2/' + model_name_plus_best_pth_tar\n","        \n","            \n","            \n","\n","        elif params.teacher == \"shufflenet_v2\":\n","            print(\"Teacher model: {}\".format(params.teacher))\n","            teacher_model = shufflenet.shufflenetv2(class_num=args.num_class).to(device)\n","            teacher_checkpoint = 'experiments/pretrained_teacher_models/base_shufflenet_v2/' + model_name_plus_best_pth_tar\n","            \n","            \n","        print('Teacher checkpoint directory : ', teacher_checkpoint)\n","        load_checkpoint(teacher_checkpoint, teacher_model)\n","\n","        # Train the model with KD\n","        logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n","        train_and_evaluate_kd(model, teacher_model, train_dl, dev_dl, optimizer, loss_fn_kd,warmup_scheduler, params, args, args.restore_file)\n","\n","    # non-KD mode: regular training to obtain a baseline model\n","    else:\n","        print(\"Train base model\")\n","        if params.model_version == \"cnn\":\n","            model = net.Net(params).to(device)\n","\n","        elif params.model_version == \"mobilenet_v2\":\n","            print(\"model: {}\".format(params.model_version))\n","            model = mobilenet.mobilenetv2(class_num=args.num_class).to(device)\n","            print(next(model.parameters()).is_cuda)\n","\n","        elif params.model_version == \"shufflenet_v2\":\n","            print(\"model: {}\".format(params.model_version))\n","            model = shufflenet.shufflenetv2(class_num=args.num_class).to(device)\n","\n","        elif params.model_version == \"alexnet\":\n","            print(\"model: {}\".format(params.model_version))\n","            model = alexnet.alexnet(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"vgg19\":\n","            print(\"model: {}\".format(params.model_version))\n","            model = models.vgg19_bn(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"googlenet\":\n","            print(\"model: {}\".format(params.model_version))\n","            model = googlenet.GoogleNet(num_class=args.num_class).to(device)\n","\n","        elif params.model_version == \"densenet121\":\n","            print(\"model: {}\".format(params.model_version))\n","            # model_name  = params.model_version\n","            # num_classes = args.num_class\n","            # feature_extract=False\n","            # model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n","            # model = model.to(device)\n","            # model = densenet.densenet121(num_class=args.num_class).to(device)\n","            model = densenet121(num_class=args.num_class).to(device)\n","\n","        elif params.model_version == \"resnet18\":\n","            model = resnet.ResNet18(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"resnet50\":\n","            print(\"model: {}\".format(params.model_version))\n","            # model_name  = 'resnet50'\n","            # num_classes = args.num_class\n","            # feature_extract=False\n","            # model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n","            # model = model.to(device)\n","        \n","            \n","            model = resnet.ResNet50(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"resnet101\":\n","            model = resnet.ResNet101(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"resnet152\":\n","            model = resnet.ResNet152(num_classes=args.num_class).to(device)\n","\n","        elif params.model_version == \"resnext29\":\n","            model = resnext.CifarResNeXt(\n","                cardinality=8, depth=29, num_classes=args.num_class).to(device)\n","            # model = nn.DataParallel(model).to(device)\n","\n","        if args.regularization:\n","            print(\">>>>>>>>>>>>>>>>>>>>>>>>Loss of Regularization>>>>>>>>>>>>>>>>>>>>>>>>\")\n","            loss_fn = loss_kd_regularization\n","        elif args.label_smoothing:\n","            print(\">>>>>>>>>>>>>>>>>>>>>>>>Label Smoothing>>>>>>>>>>>>>>>>>>>>>>>>\")\n","            loss_fn = loss_label_smoothing\n","        else:\n","            print(\">>>>>>>>>>>>>>>>>>>>>>>>Normal Training>>>>>>>>>>>>>>>>>>>>>>>>\")\n","            loss_fn = nn.CrossEntropyLoss()\n","            if args.double_training:  # double training, compare to self-KD\n","                print(\">>>>>>>>>>>>>>>>>>>>>>>>Double Training>>>>>>>>>>>>>>>>>>>>>>>>\")\n","                checkpoint = 'experiments/pretrained_teacher_models/base_' + str(params.model_version) + '/best.pth.tar'\n","                load_checkpoint(checkpoint, model)\n","\n","        if params.model_version == \"cnn\":\n","            optimizer = optim.Adam( model.parameters(), lr=params.learning_rate * (params.batch_size / 128))\n","        else:\n","            optimizer = optim.SGD(model.parameters(), lr=params.learning_rate * (params.batch_size / 128), momentum=0.9,weight_decay=5e-4)\n","\n","\n","        iter_per_epoch = len(train_dl)\n","        warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * args.warm)\n","        # Train the model\n","        logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n","        train_and_evaluate(model, train_dl, dev_dl, optimizer, loss_fn, params, args.model_dir, warmup_scheduler, args, args.restore_file)\n","\n","        \n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXy1bjGWQK35","outputId":"c6fe02b7-8f28-4718-831e-c7b17a7c1ee2"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------------------- 0 --------------------------\n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:Loading the datasets...\n"]},{"output_type":"stream","name":"stdout","text":["################## Json Params ##################\n","{\n","  \"model_version\": \"mobilenet_v2_distill\",\n","  \"subset_percent\": 1.0,\n","  \"augmentation\": \"yes\",\n","  \"teacher\": \"resnet18\",\n","  \"alpha\": 0.95,\n","  \"temperature\": 20,\n","  \"learning_rate\": 0.1,\n","  \"batch_size\": 128,\n","  \"num_epochs\": 200,\n","  \"dropout_rate\": 0.5,\n","  \"save_summary_steps\": 100,\n","  \"num_workers\": 4,\n","  \"dataset\": \"cifar100\"\n","}\n","{'alpha': 0.95,\n"," 'augmentation': 'yes',\n"," 'batch_size': 128,\n"," 'dataset': 'cifar100',\n"," 'dropout_rate': 0.5,\n"," 'learning_rate': 0.1,\n"," 'model_version': 'mobilenet_v2_distill',\n"," 'num_epochs': 100,\n"," 'num_workers': 4,\n"," 'save_summary_steps': 100,\n"," 'subset_percent': 1.0,\n"," 'teacher': 'resnet18',\n"," 'temperature': 20}\n","Random Seeder :  2320\n","Dataset Name :  cifar100   Number of classes:  100\n","Dataset Name :  ----------     cifar100     ----------\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Dataset Name :  ----------     cifar100     ----------\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:- done.\n"]},{"output_type":"stream","name":"stdout","text":["Student model: mobilenet_v2_distill\n","Teacher model: resnet18\n","Teacher checkpoint directory :  experiments/pretrained_teacher_models/base_resnet18/cifar100/best.pth.tar\n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:Starting training for 100 epoch(s)\n","INFO:root:- Eval metrics, acc:76.0300, loss: 0.0000\n","INFO:root:Epoch 1/100, lr:0.0\n"]},{"output_type":"stream","name":"stdout","text":[">>>>>>>>>The teacher accuracy: 76.03>>>>>>>>>\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:48<00:00,  8.04it/s, loss=3.805, lr=0.100000]\n","INFO:root:- Train accuracy: 6.5380, training loss: 3.8052\n","INFO:root:- Eval metrics, acc:11.1700, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 2/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:50<00:00,  7.75it/s, loss=3.369, lr=0.100000]\n","INFO:root:- Train accuracy: 15.1640, training loss: 3.3687\n","INFO:root:- Eval metrics, acc:15.3600, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 3/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:50<00:00,  7.78it/s, loss=3.065, lr=0.100000]\n","INFO:root:- Train accuracy: 22.1220, training loss: 3.0652\n","INFO:root:- Eval metrics, acc:23.5900, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 4/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:49<00:00,  7.88it/s, loss=2.836, lr=0.100000]\n","INFO:root:- Train accuracy: 27.8060, training loss: 2.8362\n","INFO:root:- Eval metrics, acc:28.6300, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 5/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:50<00:00,  7.75it/s, loss=2.669, lr=0.100000]\n","INFO:root:- Train accuracy: 32.3600, training loss: 2.6687\n","INFO:root:- Eval metrics, acc:30.6100, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 6/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:49<00:00,  7.87it/s, loss=2.537, lr=0.100000]\n","INFO:root:- Train accuracy: 35.3680, training loss: 2.5367\n","INFO:root:- Eval metrics, acc:35.3900, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 7/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:50<00:00,  7.77it/s, loss=2.426, lr=0.100000]\n","INFO:root:- Train accuracy: 38.3460, training loss: 2.4258\n","INFO:root:- Eval metrics, acc:36.7000, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 8/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:50<00:00,  7.79it/s, loss=2.342, lr=0.100000]\n","INFO:root:- Train accuracy: 40.8360, training loss: 2.3420\n","INFO:root:- Eval metrics, acc:37.1900, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 9/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:49<00:00,  7.89it/s, loss=2.283, lr=0.100000]\n","INFO:root:- Train accuracy: 42.1460, training loss: 2.2822\n","INFO:root:- Eval metrics, acc:36.8200, loss: 0.0000\n","INFO:root:Epoch 10/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.77it/s, loss=2.226, lr=0.100000]\n","INFO:root:- Train accuracy: 44.4060, training loss: 2.2258\n","INFO:root:- Eval metrics, acc:36.8100, loss: 0.0000\n","INFO:root:Epoch 11/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.82it/s, loss=2.189, lr=0.100000]\n","INFO:root:- Train accuracy: 45.4020, training loss: 2.1892\n","INFO:root:- Eval metrics, acc:43.6700, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 12/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:49<00:00,  7.90it/s, loss=2.161, lr=0.100000]\n","INFO:root:- Train accuracy: 46.1340, training loss: 2.1610\n","INFO:root:- Eval metrics, acc:34.7700, loss: 0.0000\n","INFO:root:Epoch 13/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.77it/s, loss=2.142, lr=0.100000]\n","INFO:root:- Train accuracy: 46.6320, training loss: 2.1417\n","INFO:root:- Eval metrics, acc:45.0500, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 14/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:49<00:00,  7.89it/s, loss=2.106, lr=0.100000]\n","INFO:root:- Train accuracy: 47.7160, training loss: 2.1060\n","INFO:root:- Eval metrics, acc:35.2000, loss: 0.0000\n","INFO:root:Epoch 15/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.80it/s, loss=2.083, lr=0.100000]\n","INFO:root:- Train accuracy: 48.5720, training loss: 2.0831\n","INFO:root:- Eval metrics, acc:42.0000, loss: 0.0000\n","INFO:root:Epoch 16/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.79it/s, loss=2.069, lr=0.100000]\n","INFO:root:- Train accuracy: 48.8440, training loss: 2.0691\n","INFO:root:- Eval metrics, acc:43.8600, loss: 0.0000\n","INFO:root:Epoch 17/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.89it/s, loss=2.052, lr=0.100000]\n","INFO:root:- Train accuracy: 49.4660, training loss: 2.0522\n","INFO:root:- Eval metrics, acc:33.2100, loss: 0.0000\n","INFO:root:Epoch 18/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.77it/s, loss=2.034, lr=0.100000]\n","INFO:root:- Train accuracy: 50.0240, training loss: 2.0339\n","INFO:root:- Eval metrics, acc:45.2400, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 19/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:49<00:00,  7.89it/s, loss=2.034, lr=0.100000]\n","INFO:root:- Train accuracy: 50.1440, training loss: 2.0336\n","INFO:root:- Eval metrics, acc:44.1600, loss: 0.0000\n","INFO:root:Epoch 20/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.80it/s, loss=2.027, lr=0.100000]\n","INFO:root:- Train accuracy: 49.8880, training loss: 2.0271\n","INFO:root:- Eval metrics, acc:40.8100, loss: 0.0000\n","INFO:root:Epoch 21/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.85it/s, loss=2.009, lr=0.100000]\n","INFO:root:- Train accuracy: 50.6320, training loss: 2.0091\n","INFO:root:- Eval metrics, acc:40.6300, loss: 0.0000\n","INFO:root:Epoch 22/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.95it/s, loss=1.997, lr=0.100000]\n","INFO:root:- Train accuracy: 50.9040, training loss: 1.9965\n","INFO:root:- Eval metrics, acc:44.4300, loss: 0.0000\n","INFO:root:Epoch 23/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.84it/s, loss=1.991, lr=0.100000]\n","INFO:root:- Train accuracy: 51.2180, training loss: 1.9908\n","INFO:root:- Eval metrics, acc:44.7400, loss: 0.0000\n","INFO:root:Epoch 24/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.94it/s, loss=1.986, lr=0.100000]\n","INFO:root:- Train accuracy: 51.5200, training loss: 1.9861\n","INFO:root:- Eval metrics, acc:41.7800, loss: 0.0000\n","INFO:root:Epoch 25/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.81it/s, loss=1.981, lr=0.100000]\n","INFO:root:- Train accuracy: 51.4580, training loss: 1.9808\n","INFO:root:- Eval metrics, acc:50.1300, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 26/100, lr:0.09999999999744245\n","100%|██████████| 391/391 [00:50<00:00,  7.81it/s, loss=1.969, lr=0.100000]\n","INFO:root:- Train accuracy: 51.5500, training loss: 1.9691\n","INFO:root:- Eval metrics, acc:44.4300, loss: 0.0000\n","INFO:root:Epoch 27/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.93it/s, loss=1.971, lr=0.100000]\n","INFO:root:- Train accuracy: 51.8520, training loss: 1.9709\n","INFO:root:- Eval metrics, acc:42.3800, loss: 0.0000\n","INFO:root:Epoch 28/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.80it/s, loss=1.973, lr=0.100000]\n","INFO:root:- Train accuracy: 51.6120, training loss: 1.9729\n","INFO:root:- Eval metrics, acc:44.0500, loss: 0.0000\n","INFO:root:Epoch 29/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.78it/s, loss=1.964, lr=0.100000]\n","INFO:root:- Train accuracy: 52.2720, training loss: 1.9636\n","INFO:root:- Eval metrics, acc:39.5400, loss: 0.0000\n","INFO:root:Epoch 30/100, lr:0.09999999999744245\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.92it/s, loss=1.955, lr=0.100000]\n","INFO:root:- Train accuracy: 52.0740, training loss: 1.9555\n","INFO:root:- Eval metrics, acc:44.2800, loss: 0.0000\n","INFO:root:Epoch 31/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.83it/s, loss=1.583, lr=0.020000]\n","INFO:root:- Train accuracy: 61.8760, training loss: 1.5830\n","INFO:root:- Eval metrics, acc:63.3200, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 32/100, lr:0.019999999999488493\n","100%|██████████| 391/391 [00:49<00:00,  7.92it/s, loss=1.469, lr=0.020000]\n","INFO:root:- Train accuracy: 64.8300, training loss: 1.4693\n","INFO:root:- Eval metrics, acc:63.8800, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 33/100, lr:0.019999999999488493\n","100%|██████████| 391/391 [00:50<00:00,  7.80it/s, loss=1.430, lr=0.020000]\n","INFO:root:- Train accuracy: 66.1260, training loss: 1.4296\n","INFO:root:- Eval metrics, acc:64.6500, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 34/100, lr:0.019999999999488493\n","100%|██████████| 391/391 [00:49<00:00,  7.83it/s, loss=1.399, lr=0.020000]\n","INFO:root:- Train accuracy: 67.1780, training loss: 1.3986\n","INFO:root:- Eval metrics, acc:64.6300, loss: 0.0000\n","INFO:root:Epoch 35/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.95it/s, loss=1.381, lr=0.020000]\n","INFO:root:- Train accuracy: 68.0460, training loss: 1.3815\n","INFO:root:- Eval metrics, acc:64.2000, loss: 0.0000\n","INFO:root:Epoch 36/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.81it/s, loss=1.368, lr=0.020000]\n","INFO:root:- Train accuracy: 68.3020, training loss: 1.3681\n","INFO:root:- Eval metrics, acc:63.5200, loss: 0.0000\n","INFO:root:Epoch 37/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.80it/s, loss=1.365, lr=0.020000]\n","INFO:root:- Train accuracy: 68.7080, training loss: 1.3651\n","INFO:root:- Eval metrics, acc:64.0400, loss: 0.0000\n","INFO:root:Epoch 38/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.92it/s, loss=1.359, lr=0.020000]\n","INFO:root:- Train accuracy: 68.9400, training loss: 1.3590\n","INFO:root:- Eval metrics, acc:64.5400, loss: 0.0000\n","INFO:root:Epoch 39/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.82it/s, loss=1.353, lr=0.020000]\n","INFO:root:- Train accuracy: 69.0300, training loss: 1.3524\n","INFO:root:- Eval metrics, acc:65.2500, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 40/100, lr:0.019999999999488493\n","100%|██████████| 391/391 [00:49<00:00,  7.90it/s, loss=1.353, lr=0.020000]\n","INFO:root:- Train accuracy: 69.3340, training loss: 1.3527\n","INFO:root:- Eval metrics, acc:64.4000, loss: 0.0000\n","INFO:root:Epoch 41/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.81it/s, loss=1.344, lr=0.020000]\n","INFO:root:- Train accuracy: 69.4980, training loss: 1.3441\n","INFO:root:- Eval metrics, acc:63.0000, loss: 0.0000\n","INFO:root:Epoch 42/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.82it/s, loss=1.340, lr=0.020000]\n","INFO:root:- Train accuracy: 69.8540, training loss: 1.3398\n","INFO:root:- Eval metrics, acc:62.4300, loss: 0.0000\n","INFO:root:Epoch 43/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.90it/s, loss=1.330, lr=0.020000]\n","INFO:root:- Train accuracy: 70.3180, training loss: 1.3301\n","INFO:root:- Eval metrics, acc:64.4500, loss: 0.0000\n","INFO:root:Epoch 44/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.79it/s, loss=1.335, lr=0.020000]\n","INFO:root:- Train accuracy: 69.9000, training loss: 1.3346\n","INFO:root:- Eval metrics, acc:63.1900, loss: 0.0000\n","INFO:root:Epoch 45/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.80it/s, loss=1.331, lr=0.020000]\n","INFO:root:- Train accuracy: 70.4060, training loss: 1.3309\n","INFO:root:- Eval metrics, acc:63.9900, loss: 0.0000\n","INFO:root:Epoch 46/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.89it/s, loss=1.326, lr=0.020000]\n","INFO:root:- Train accuracy: 70.5060, training loss: 1.3265\n","INFO:root:- Eval metrics, acc:64.5100, loss: 0.0000\n","INFO:root:Epoch 47/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.78it/s, loss=1.325, lr=0.020000]\n","INFO:root:- Train accuracy: 70.2980, training loss: 1.3253\n","INFO:root:- Eval metrics, acc:63.8900, loss: 0.0000\n","INFO:root:Epoch 48/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.82it/s, loss=1.329, lr=0.020000]\n","INFO:root:- Train accuracy: 70.4640, training loss: 1.3289\n","INFO:root:- Eval metrics, acc:64.2700, loss: 0.0000\n","INFO:root:Epoch 49/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.91it/s, loss=1.318, lr=0.020000]\n","INFO:root:- Train accuracy: 70.8920, training loss: 1.3177\n","INFO:root:- Eval metrics, acc:61.4600, loss: 0.0000\n","INFO:root:Epoch 50/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.79it/s, loss=1.316, lr=0.020000]\n","INFO:root:- Train accuracy: 70.7560, training loss: 1.3161\n","INFO:root:- Eval metrics, acc:62.6100, loss: 0.0000\n","INFO:root:Epoch 51/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.91it/s, loss=1.318, lr=0.020000]\n","INFO:root:- Train accuracy: 70.7320, training loss: 1.3185\n","INFO:root:- Eval metrics, acc:60.0600, loss: 0.0000\n","INFO:root:Epoch 52/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.92it/s, loss=1.307, lr=0.020000]\n","INFO:root:- Train accuracy: 71.1840, training loss: 1.3065\n","INFO:root:- Eval metrics, acc:62.8000, loss: 0.0000\n","INFO:root:Epoch 53/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.80it/s, loss=1.299, lr=0.020000]\n","INFO:root:- Train accuracy: 71.3480, training loss: 1.2988\n","INFO:root:- Eval metrics, acc:64.2400, loss: 0.0000\n","INFO:root:Epoch 54/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.92it/s, loss=1.297, lr=0.020000]\n","INFO:root:- Train accuracy: 71.5800, training loss: 1.2973\n","INFO:root:- Eval metrics, acc:64.2600, loss: 0.0000\n","INFO:root:Epoch 55/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.81it/s, loss=1.292, lr=0.020000]\n","INFO:root:- Train accuracy: 71.8760, training loss: 1.2923\n","INFO:root:- Eval metrics, acc:58.7400, loss: 0.0000\n","INFO:root:Epoch 56/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.83it/s, loss=1.288, lr=0.020000]\n","INFO:root:- Train accuracy: 72.0280, training loss: 1.2875\n","INFO:root:- Eval metrics, acc:64.7900, loss: 0.0000\n","INFO:root:Epoch 57/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.94it/s, loss=1.289, lr=0.020000]\n","INFO:root:- Train accuracy: 71.9040, training loss: 1.2885\n","INFO:root:- Eval metrics, acc:62.8900, loss: 0.0000\n","INFO:root:Epoch 58/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.81it/s, loss=1.289, lr=0.020000]\n","INFO:root:- Train accuracy: 71.6980, training loss: 1.2890\n","INFO:root:- Eval metrics, acc:64.2500, loss: 0.0000\n","INFO:root:Epoch 59/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:50<00:00,  7.82it/s, loss=1.276, lr=0.020000]\n","INFO:root:- Train accuracy: 72.0220, training loss: 1.2760\n","INFO:root:- Eval metrics, acc:63.2100, loss: 0.0000\n","INFO:root:Epoch 60/100, lr:0.019999999999488493\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.92it/s, loss=1.275, lr=0.020000]\n","INFO:root:- Train accuracy: 72.3020, training loss: 1.2745\n","INFO:root:- Eval metrics, acc:61.4000, loss: 0.0000\n","INFO:root:Epoch 61/100, lr:0.003999999999897699\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:49<00:00,  7.83it/s, loss=1.074, lr=0.004000]\n","INFO:root:- Train accuracy: 78.4560, training loss: 1.0743\n","INFO:root:- Eval metrics, acc:71.0400, loss: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint Directory exists! \n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:*********** Hurray ! Found new best accuracy *****************\n","INFO:root:Epoch 62/100, lr:0.003999999999897699\n"," 53%|█████▎    | 206/391 [00:26<00:22,  8.06it/s, loss=1.019, lr=0.004000]"]}],"source":["if __name__ == \"__main__\":\n","  i =0\n","  while(i<3):\n","    print('--------------------------',i,'--------------------------')\n","    main()\n","    i+=1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSkadoZSBHZ5"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46PltwZtBHZ6"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"dynamic_rectification_knowledge_distillation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"nbformat":4,"nbformat_minor":0}